{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<span style=\"color: rgb(0,53,91);\">\n",
    "<center><img src=\"./Imagenes/ITESO_Logo.png\" style=\"width:500px;height:142px;\" title=\"Logo ITESO\"></center>\n",
    "<font face = \"Times New Roman\" size = \"6\"><b><center>Maestría en Sistemas Computacionales</center></b></font>\n",
    "<font face = \"Times New Roman\" size = \"5\"><b><center>Programación para Análisis de Datos</center></b></font>\n",
    "\n",
    "<b><br><font face = \"Times New Roman\" size = \"4\"><center>Unidad 2: Conceptos Generales</center></font>\n",
    "<font face = \"Times New Roman\" size = \"4\"><center>Tema 2.6: Conceptos del Procesamiento de Imágenes</center></font>\n",
    "<font face = \"Times New Roman\" size = \"4\"><center>Subtema d: Clasificación en Cascada</center></font></b>\n",
    "<div align=\"right\"><font face = \"Times New Roman\" size = \"2\">Dr. Iván Esteban Villalón Turrubiates (villalon@iteso.mx)</font></div>\n",
    "</span></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rOG12Rey7g9C"
   },
   "source": [
    "## CLASIFICACIÓN EN CASCADA\n",
    "\n",
    "Una de las principales aplicaciones de la visión computacional y del procesamiento de imágenes es la detección de objetos.\n",
    "\n",
    "La detección de objetos empleando **Clasificación en Cascada** basada en el modelo HAAR (*Haar Wavelet*), es una metodología efectiva de detección que fue propuesta por ***Paul Viola*** y ***Michael Jones*** en un artículo del 2001 que puede ser consultado [en esta liga](https://www.cs.cmu.edu/~efros/courses/LBMV07/Papers/viola-cvpr-01.pdf). \n",
    "\n",
    "Posteriormente, ***Rainer Lienhart***, ***Alexander Kuranov*** y ***Vadim Pisarevsky*** lo implementaron y mejoraron en 2002 con una propuesta que puede ser consultada [en esta liga](http://www.staroceans.org/documents/MRL-TR-May02-revised-Dec02.pdf).\n",
    "\n",
    "La **Clasificación en Cascada** es una aproximación basada en **Aprendizaje Máquina (Machine Learning)** donde una función en cascada es entrenada a partir de un banco de imágenes con valores positivos y negativos. Posteriormente se emplea para la detección de objetos en otras imágenes.\n",
    "\n",
    "Por otro lado, **OpenCV** provee un método de entrenamiento con modelos pre-entrenados, los cuales se han instalado con la librería **OpenCV** dentro de la carpeta `Data`, sin embargo, también pueden ser descargados desde [este enlace](https://github.com/opencv/opencv/tree/3.4/data/haarcascades).\n",
    "\n",
    "La teoría detallada sobre la **Clasificación en Cascada** puede consultarse a través [de esta liga](https://docs.opencv.org/3.4/db/d28/tutorial_cascade_classifier.html).\n",
    "\n",
    "Existe un tutorial detallado sobre el uso de la **Clasificación en Cascada** en **OpenCV**, el cual puede consultarse a través [de esta liga](https://docs.opencv.org/3.4/dc/d88/tutorial_traincascade.html).\n",
    "\n",
    "En este subtema se describen algunos principios básicos de la **Clasificación en Cascada** empleando **OpenCV**.\n",
    "\n",
    "Para ello, se realizará la carga de la imagen con los siguientes pasos:\n",
    "\n",
    "1. Se cargan las librerías `OpenCV`, `PyLab`, `NumPy` y `Matplotlib`.\n",
    "2. Se define el método `.rcParams()` de **PyLab** para visualizar la imagen con mejor tamaño.\n",
    "3. Se lee el archivo `Grupo.jpg`.\n",
    "4. Se convierte del modo `BGR` a `RGB`.\n",
    "5. Se convierte del modo `RGB` a `Escala de Grises` ya que se usarán ambos.\n",
    "7. Se imprime la imagen para verificación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dvzQbnbX7g9D"
   },
   "outputs": [],
   "source": [
    "#Importación de Librerías\n",
    "import cv2 \n",
    "import pylab \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Tamaño de la Imagen\n",
    "pylab.rcParams['figure.figsize'] = (10.0, 10.0) \n",
    "\n",
    "#Lectura de la Imagen desde un archivo JPG\n",
    "Imagen = cv2.imread(\"./Imagenes/Grupo.jpg\")    \n",
    "\n",
    "#Modificación del Espacio de Color\n",
    "Grupo = cv2.cvtColor(Imagen, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "#Imagen en Escala de Grises\n",
    "Gris = cv2.cvtColor(Grupo, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "#Impresión de la Imagen\n",
    "plt.imshow(Grupo)\n",
    "plt.axis('off')\n",
    "plt.title(\"Grupo de Personas\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1_Z8K7oEZmcA"
   },
   "source": [
    "### Detección de Caras\n",
    "Se empleará el modelo pre-entrenado para la detección de caras en la imagen. Este modelo está almacenado en el archivo `haarcascade_frontalface_default.xml` dentro de la carpeta `Modelos`. \n",
    "\n",
    "Para ello se debe de cargar el modelo pre-entrenado empleando el método `.CascadeClassifier()`, cuyo argumento es el nombre del archivo `XML` que contiene el entrenamiento.\n",
    "\n",
    "Posteriormente se aplicará el método `.detectMultiScale(a,b,c)` el cual detecta objetos de diferentes tamaños desde la imagen de entrada con base en el modelo pre-entrenado, y los regresa como una lista de rectángulos. Sus argumentos son:\n",
    "\n",
    "* El argumento `a`: Indica el nombre de la variable que contiene a la imagen en escala de grises.\n",
    "* El argumento `b`: Indica el factor de escalamiento, es el tamaño de la reducción en cada iteración.\n",
    "* El argumento `c`: Indica los vecindarios que cada rectángulo debe tener para mantenerlo.\n",
    "\n",
    "La documentación detallada del método `.detectMultiScale()` se puede consultar [en esta liga](https://docs.opencv.org/3.4/d1/de5/classcv_1_1CascadeClassifier.html#aaf8181cb63968136476ec4204ffca498).\n",
    "\n",
    "Para este ejemplo emplearemos la imagen `Grupo` en escala de grises para que sea más correcta la determinación de la operación de **Detección de Caras**, esto es:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "colab_type": "code",
    "id": "4jO3yBlq7g9I",
    "outputId": "939e90b5-7462-4fce-b1c8-af754760027e"
   },
   "outputs": [],
   "source": [
    "#Lectura del Modelo Pre-Entrenado\n",
    "modelo_caras = cv2.CascadeClassifier('./Modelos/haarcascade_frontalface_default.xml')\n",
    "\n",
    "#Operación de Detección de Caras \n",
    "caras = modelo_caras.detectMultiScale(Gris, 1.3, 5)\n",
    "\n",
    "#Inserción de Rectángulos en la Imagen\n",
    "for (x,y,w,h) in caras:\n",
    "     cv2.rectangle(Grupo,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "\n",
    "#Impresión de la Imagen\n",
    "plt.imshow(Grupo)\n",
    "plt.axis('off')\n",
    "plt.title(\"Detección de Caras\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YKnlOgEpaelS"
   },
   "source": [
    "### Detección de Sonrisas\n",
    "Se empleará el modelo pre-entrenado para la detección de sonrisas en la imagen. Este modelo está almacenado en el archivo `haarcascade_smile.xml` dentro de la carpeta `Modelos`. Para ello se debe de cargar el modelo pre-entrenado empleando el método `.CascadeClassifier()`, cuyo argumento es el nombre del archivo `XML` que contiene el entrenamiento.\n",
    "\n",
    "Para este ejemplo emplearemos la imagen `Grupo` en escala de grises para que sea más correcta la determinación de la operación de **Detección de Sorisas**, esto es:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "colab_type": "code",
    "id": "T2JCR1Z47g9L",
    "outputId": "8a799258-ff95-4c71-d771-7445d002be3b"
   },
   "outputs": [],
   "source": [
    "#Nueva Lectura de la Imagen Original\n",
    "Prueba = cv2.cvtColor(cv2.imread(\"./Imagenes/Grupo.jpg\"), cv2.COLOR_BGR2RGB)   \n",
    "\n",
    "#Lectura del Modelo Pre-Entrenado\n",
    "modelo_risas = cv2.CascadeClassifier('./Modelos/haarcascade_smile.xml')\n",
    "\n",
    "#Operación de Detección de Sonrisas\n",
    "risas = modelo_risas.detectMultiScale(Gris, 1.3, 15)\n",
    "\n",
    "#Inserción de Rectángulos en la Imagen\n",
    "for (x,y,w,h) in risas:\n",
    "     cv2.rectangle(Prueba,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "\n",
    "#Impresión de la Imagen\n",
    "plt.imshow(Prueba)\n",
    "plt.axis('off')\n",
    "plt.title(\"Detección de Sonrisas\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_IEdRb4-gU3a"
   },
   "source": [
    "Del resultado obtenido, es posible ver que se detectaron las sonrisas de manera adecuada, pero también hay *falsos positivos* y *falsos negativos* como es usual en la aplicación del modelo de **Clasificación en Cascada**. \n",
    "\n",
    "Por lo tanto, para mejorar este proceso, se considerarán solamente las sonrisas dentro de las caras que fueron detectadas con anterioridad, esto es:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "colab_type": "code",
    "id": "FLkwpkNUgUQC",
    "outputId": "1394edd7-3309-45ca-f653-12b019162e6a"
   },
   "outputs": [],
   "source": [
    "#Operación de Detección de Sonrisas en Caras\n",
    "for (x,y,w,h) in caras:\n",
    "  for (x_s,y_s,w_s,h_s) in risas:\n",
    "    if( (x <= x_s) and (y <= y_s) and ( x+w >= x_s+w_s) and ( y+h >= y_s+h_s)):\n",
    "      cv2.rectangle(Grupo, (x_s,y_s),(x_s+w_s,y_s+h_s),(0,255,0),2)\n",
    "\n",
    "#Impresión de la Imagen\n",
    "plt.imshow(Grupo)\n",
    "plt.axis('off')\n",
    "plt.title(\"Detección de Caras y Sonrisas\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0aUWvPsHi6zH"
   },
   "source": [
    "### Detección de Ojos\n",
    "Se empleará el modelo pre-entrenado para la detección de ojos en la imagen. Este modelo está almacenado en el archivo `haarcascade_frontalface_default.xml` dentro de la carpeta `Modelos`. Para ello se debe de cargar el modelo pre-entrenado empleando el método `.CascadeClassifier()`, cuyo argumento es el nombre del archivo `XML` que contiene el entrenamiento.\n",
    "\n",
    "Para este ejemplo emplearemos la imagen `Grupo` en escala de grises para que sea más correcta la determinación de la operación de **Detección de Ojos**, esto es:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "colab_type": "code",
    "id": "3Jfn5Ml7i7RW",
    "outputId": "a0daba06-9a10-4ee7-e755-42da5d7d1326"
   },
   "outputs": [],
   "source": [
    "#Nueva Lectura de la Imagen Original\n",
    "Prueba = cv2.cvtColor(cv2.imread(\"./Imagenes/Grupo.jpg\"), cv2.COLOR_BGR2RGB) \n",
    "\n",
    "#Lectura del Modelo Pre-Entrenado\n",
    "modelo_ojos = cv2.CascadeClassifier('./Modelos/haarcascade_eye.xml')\n",
    "\n",
    "#Operación de Detección de Ojos\n",
    "ojos = modelo_ojos.detectMultiScale(Gris, 1.3, 1)\n",
    "\n",
    "#Inserción de Rectángulos en la Imagen\n",
    "for (x,y,w,h) in ojos:\n",
    "     cv2.rectangle(Prueba,(x,y),(x+w,y+h),(255,255,255),2)\n",
    "\n",
    "#Impresión de la Imagen\n",
    "plt.imshow(Prueba)\n",
    "plt.axis('off')\n",
    "plt.title(\"Detección de Ojos\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dJBm-N5NlS-I"
   },
   "source": [
    "De manera similar al resultado obtenido de la clasificación de sonrisas, es posible ver que se detectaron los ojos de manera adecuada, pero también hay *falsos positivos* y *falsos negativos* como es usual en la aplicación del modelo de **Clasificación en Cascada**. \n",
    "\n",
    "Por lo tanto, para mejorar este proceso, se considerarán solamente los ojos dentro de las caras que fueron detectadas con anterioridad, esto es:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "colab_type": "code",
    "id": "2fNq-l4TlT9k",
    "outputId": "d96c9f1a-0e45-4b49-ab46-4c161f9de602"
   },
   "outputs": [],
   "source": [
    "#Operación de Detección de Ojos en Caras\n",
    "for (x,y,w,h) in caras:\n",
    "  for (x_s,y_s,w_s,h_s) in ojos:\n",
    "    if( (x <= x_s) and (y <= y_s) and ( x+w >= x_s+w_s) and ( y+h >= y_s+h_s)):\n",
    "      cv2.rectangle(Grupo, (x_s,y_s),(x_s+w_s,y_s+h_s),(255,255,255),2)\n",
    "\n",
    "#Impresión de la Imagen\n",
    "plt.imshow(Grupo)\n",
    "plt.axis('off')\n",
    "plt.title(\"Detección de Caras, Sonrisas y Ojos\")\n",
    "#plt.imsave('./Guardados/Grupo_Clas.jpg', Grupo)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Wza2EK6lkSI1"
   },
   "source": [
    "### Técnicas Modernas de Reconocimiento de Objetos\n",
    "A pesar de que la mayoría de las aplicaciones de detección de objetos han sido reemplazados en la actualidad por soluciones basadas en modelos de **Aprendizaje Profundo (Deep Learning)** como las **Redes Neuronales Convolucionales (Convolutional Neural Networks)** cuyo proceso de creación y entrenamiento se aplican en plataformas como ***Tensorflow*** (tema que se abordará brevemente al final de curso), el método mostrado para detección de caras es muy empleado por su facilidad de uso así como su rapidez, empleando **OpenCV** como su plataforma base."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5NcnvPVw7g9N"
   },
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>.: Fin del Tema :.</b>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "4-Cascade_classification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
